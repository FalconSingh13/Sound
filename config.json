{
    "version": "0.5",
    "created_at": "2025-03-19:19:00.000000",
    "random_seed": 8374,
    "model": {
        "encoder": {
            "n_layer": 12,
            "n_embd": 1024,
            "n_hidden": 4096,
            "n_head": 16,
            "head_dim": 128
        },
        "decoder": {
            "n_layer": 18,
            "n_embd": 2048,
            "n_hidden": 8192,
            "gqa_query_heads": 16,
            "cross_query_heads": 16,
            "kv_heads": 4,
            "gqa_head_dim": 128,
            "cross_head_dim": 128
        },
        "linear": {
            "fused_mlp": true,
            "mlp_activations": [
                "silu",
                "linear"
            ]
        },
        "expert": {
            "num_experts": 1,
            "num_experts_per_tok": 1,
            "moe_mlp_dim": 2048,
            "shared_experts": 1
        },
        "embed": {
            "use_iota_embed": false,
            "normalize_embedding_logits": true
        },
        "src_vocab_size": 256,
        "tgt_vocab_size": 1028,
        "dropout": 0.0,
        "rope_theta": 10000.0
    },
    "parallelism": {
        "data_parallelism": 1,
        "fsdp_parallelism": 1,
        "fsdp_transpose_parallelism": 1,
        "sequence_parallelism": 1,
        "context_parallelism": 1,
        "tensor_parallelism": 1,
        "tensor_transpose_parallelism": 1,
        "tensor_sequence_parallelism": 1,
        "autoregressive_parallelism": 1,
        "pipeline_parallelism": 1,
        "expert_parallelism": 1,
        "mesh_axes": [
            "data",
            "fsdp",
            "stage",
            "fsdp_transpose",
            "sequence",
            "context",
            "tensor",
            "tensor_transpose",
            "tensor_sequence",
            "expert",
            "autoregressive"
        ],
        "data_sharding": [
            [
                "data",
                "stage",
                "fsdp",
                "fsdp_transpose",
                "sequence",
                "context",
                "tensor",
                "tensor_transpose",
                "tensor_sequence",
                "expert",
                "autoregressive"
            ]
        ],
        "logical_axis_rules": [
            [
                "activation_batch",
                [
                    "data",
                    "fsdp",
                    "fsdp_transpose",
                    "expert"
                ]
            ],
            [
                "activation_batch_no_exp",
                [
                    "data",
                    "fsdp",
                    "fsdp_transpose"
                ]
            ],
            [
                "activation_embed_and_logits_batch",
                [
                    "data",
                    "stage",
                    "fsdp",
                    "fsdp_transpose",
                    "expert"
                ]
            ],
            [
                "activation_heads",
                [
                    "tensor",
                    "tensor_transpose",
                    "sequence",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "activation_kv_heads",
                [
                    "tensor",
                    "tensor_transpose",
                    "sequence",
                    "tensor_sequence"
                ]
            ],
            [
                "activation_length",
                [
                    "sequence"
                ]
            ],
            [
                "activation_norm_length",
                [
                    "tensor_sequence",
                    "sequence"
                ]
            ],
            [
                "activation_embed",
                [
                    "tensor",
                    "tensor_transpose"
                ]
            ],
            [
                "activation_mlp",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence"
                ]
            ],
            [
                "activation_kv",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence"
                ]
            ],
            [
                "activation_prefill_kv_batch",
                [
                    "data",
                    "fsdp",
                    "fsdp_transpose",
                    "expert"
                ]
            ],
            [
                "activation_kv_batch",
                [
                    "data",
                    "fsdp",
                    "fsdp_transpose",
                    "expert"
                ]
            ],
            [
                "activation_kv_head_dim",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence"
                ]
            ],
            [
                "activation_vocab",
                [
                    "tensor",
                    "tensor_transpose",
                    "sequence",
                    "tensor_sequence"
                ]
            ],
            [
                "activation_vocab",
                [
                    "tensor",
                    "tensor_transpose"
                ]
            ],
            [
                "activation_vocab",
                "tensor_sequence"
            ],
            [
                "activation_vocab",
                [
                    "sequence"
                ]
            ],
            [
                "activation_stage",
                "stage"
            ],
            [
                "activation_exp",
                [
                    "expert"
                ]
            ],
            [
                "decode_batch",
                [
                    "data",
                    "fsdp",
                    "fsdp_transpose",
                    "expert"
                ]
            ],
            [
                "decode_length",
                [
                    "sequence"
                ]
            ],
            [
                "mlp",
                [
                    "fsdp_transpose",
                    "tensor",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "vocab",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "heads",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "q_heads",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "kv_heads",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence",
                    "autoregressive"
                ]
            ],
            [
                "embed",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "embed",
                [
                    "fsdp",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "embed",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "embed",
                [
                    "fsdp",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "embed_no_exp",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "tensor_transpose"
                ]
            ],
            [
                "embed_no_exp",
                [
                    "fsdp",
                    "sequence",
                    "tensor_transpose"
                ]
            ],
            [
                "embed_no_exp",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence"
                ]
            ],
            [
                "embed_no_exp",
                [
                    "fsdp",
                    "sequence"
                ]
            ],
            [
                "q_lora",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "q_lora",
                [
                    "fsdp",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "q_lora",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "q_lora",
                [
                    "fsdp",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "kv_lora",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "kv_lora",
                [
                    "fsdp",
                    "sequence",
                    "tensor_transpose",
                    "expert"
                ]
            ],
            [
                "kv_lora",
                [
                    "fsdp",
                    "fsdp_transpose",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "kv_lora",
                [
                    "fsdp",
                    "sequence",
                    "expert"
                ]
            ],
            [
                "norm",
                [
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence"
                ]
            ],
            [
                "layers",
                "stage"
            ],
            [
                "kv",
                []
            ],
            [
                "kv_head_dim",
                []
            ],
            [
                "cache_batch_prefill",
                []
            ],
            [
                "cache_batch",
                []
            ],
            [
                "cache_heads",
                [
                    "autoregressive",
                    "tensor",
                    "tensor_transpose",
                    "tensor_sequence"
                ]
            ],
            [
                "cache_heads",
                [
                    "autoregressive",
                    "tensor",
                    "tensor_sequence"
                ]
            ],
            [
                "cache_kv",
                []
            ],
            [
                "cache_sequence",
                []
            ],
            [
                "exp",
                "expert"
            ],
            [
                "paged_kv_heads",
                []
            ],
            [
                "num_pages",
                [
                    "tensor"
                ]
            ],
            [
                "tokens_per_page",
                []
            ],
            [
                "paged_kv_head_dim_size",
                []
            ]
        ],
        "num_layers_per_pipeline_stage": 1,
        "num_pipeline_repeats": -1,
        "num_pipeline_microbatches": -1,
        "pipeline_delay_activation_forwarding": false,
        "pipeline_fsdp_ag_once": false,
        "scan_pipeline_iterations": true,
        "set_remat_policy_on_pipeline_iterations": true,
        "set_remat_policy_on_layers_per_stage": false
    },
    "inference": {
        "guidance_scale": 3.0
    },
    "profiler": {
        "enabled": true,
        "period": 0,
        "skip_first_n_steps": 50,
        "steps": 5
    },
    "quantization": {
        "quantization": "",
        "quant_cfg_path": "",
        "replicate_quant_scale": false,
        "quantize_kvcache": false,
        "kv_quant_axis": "heads_and_dkv",
        "kv_quant_dtype": "int8",
        "quantization_local_shard_count": -1
    },
    "training": {
        "global_batch_size": 256,
        "max_steps": 100000,
        "eval_every_steps": 500,
        "val_steps": 18,
        "val_d_steps": 18,
        "learning_rate": 0.0004,
        "warmup_steps": 2000,
        "weight_decay": 0.1,
        "lr_decay_steps": 20000,
        "min_lr": 0.00001,
        "beta1": 0.9,
        "beta2": 0.95,
        "loss_scale": 1.0,
        "unconditional_training_prob": 0.15,
        "g_accum_iters": 1,
        "encoder_remat_policy": "save_qkv_proj",
        "decoder_remat_policy": "save_qkv_proj"
    },
    "data_paths": {
        "train_dir": "/home/nari/data/train",
        "val_dir": "/home/nari/data/val",
        "val_d_dir": "/home/nari/data/val_d"
    },
    "data": {
        "text_length": 1024,
        "audio_length": 3072,
        "channels": 9,
        "text_pad_value": 0,
        "audio_eos_value": 1024,
        "audio_pad_value": 1025,
        "audio_bos_value": 1026,
        "delay_pattern": [
            0,
            8,
            9,
            10,
            11,
            12,
            13,
            14,
            15
        ]
    }
}